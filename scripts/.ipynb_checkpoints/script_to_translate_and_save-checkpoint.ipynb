{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PEG0unNd_3Rb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pcorrea/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#importando as bibliotecas \n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import spacy as sp\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "from textblob import TextBlob\n",
    "import sys\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'sentimental_ds'...\n",
      "remote: Enumerating objects: 3, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 98 (delta 0), reused 2 (delta 0), pack-reused 95\u001b[K\n",
      "Unpacking objects: 100% (98/98), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/paulordie/sentimental_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'sentimental_ds/'\n",
      "/home/pcorrea/Documents/Ciencia-De-Dados-UEA/script_presitence_sentimental/sentimental_ds\n",
      "dados-curso.csv        main.txt           piloto-2.ipynb\r\n",
      "dataset-v2.dat         pc-dataset-v2.csv  prototype_sentimental_analyzer.ipynb\r\n",
      "first_code_test.ipynb  pc-dataset-v2.dat  README.md\r\n"
     ]
    }
   ],
   "source": [
    "%cd sentimental_ds/\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo do dado:  <class '_io.TextIOWrapper'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "dados = open('dataset-v2.dat', encoding=\"utf8\") #pandas\n",
    "print(\"Tipo do dado: \", type(dados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfDataBase = list()\n",
    "listOfData = []\n",
    " \n",
    "def findKeys(dataBase):\n",
    "    for register in dataBase:\n",
    "        try:\n",
    "            cols = register.split('\\n')\n",
    "            listOfDataBase.append(cols[0])\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Error on uncode decode findkeys\")\n",
    "    print(\"Find Keys: \",listOfDataBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jFse6OkPzyuA",
    "outputId": "b0953b74-093b-43e1-8791-6855e4ac2743"
   },
   "outputs": [],
   "source": [
    "def passToJson():\n",
    "    i=0\n",
    "    for i in range(100000): ## tem que colocar a array de todo arquivo\n",
    "        listOfIssue = listOfDataBase[i]\n",
    "        i+=1\n",
    "#         time.sleep(1)\n",
    "        joinList = json.loads(listOfIssue)\n",
    "        data = pd.json_normalize(joinList)\n",
    "        listOfData.append(data)\n",
    "    return listOfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f301b04cc826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mvalueFindKeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdados\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#valor que vai para def passToJson()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdictionaryOfDate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpassToJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-5b21730f1e41>\u001b[0m in \u001b[0;36mpassToJson\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         time.sleep(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mjoinList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistOfIssue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoinList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mlistOfData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlistOfData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/json/_normalize.py\u001b[0m in \u001b[0;36m_json_normalize\u001b[0;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep, max_level)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;31m#       reasonably\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_to_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mrecord_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrecord_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    473\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                     \u001b[0;31m# set the index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   5356\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5358\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 \u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_cast_data_without_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                     return cls(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_maybe_cast_data_without_dtype\u001b[0;34m(subarr)\u001b[0m\n\u001b[1;32m   5477\u001b[0m     \"\"\"\n\u001b[1;32m   5478\u001b[0m     \u001b[0;31m# Runtime import needed bc IntervalArray imports Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5479\u001b[0;31m     from pandas.core.arrays import (\n\u001b[0m\u001b[1;32m   5480\u001b[0m         \u001b[0mIntervalArray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5481\u001b[0m         \u001b[0mPeriodArray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def showContent(value, collum):\n",
    "    i=0\n",
    "    _data = []\n",
    "    for i in range(value): ##range que vai trazer todas as colunas\n",
    "        try:\n",
    "            res = listOfData[i][collum]\n",
    "            print(type(res))\n",
    "            print(listOfData[i][collum]) #averageRating, ratingValue etc\n",
    "            i = i + 1\n",
    "            print(\"line: \", i)\n",
    "        except KeyError:\n",
    "            print(\"Key Error\")\n",
    "            continue\n",
    "\n",
    "valueFindKeys = findKeys(dados) #valor que vai para def passToJson()\n",
    "dictionaryOfDate = passToJson()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(objs=dictionaryOfDate,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100256"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 4].values\n",
    "type(X)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tripadvisor(tweet):\n",
    "    tweet = BeautifulSoup(tweet, 'lxml').get_text() # o lxml indica o parse pode ser usado para dados de web por ex\n",
    "#     tweet = re.sub(r\"\\b\\.\\s\\\\n\", '\\n', tweet)\n",
    "#     tweet = re.sub(r\"\\b\\.\\s[A-Za-z0-9]\", '\\n', tweet)\n",
    "    tweet = re.sub(r\"\\b\\.\\s\\\\n\", '. \\n', tweet)\n",
    "    tweet = re.sub(r\"\\b\\.\", '. \\n', tweet)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivoToSave = '/home/pcorrea/salvo.txt'\n",
    "\n",
    "def saveDocument(var,resultado,nota,fim):\n",
    "    try:\n",
    "        with open(arquivoToSave, 'a') as toSave:\n",
    "            toSave.write('{} - {} : {} \\n'.format(var,resultado,nota))\n",
    "            if fim == \"fim\":\n",
    "                toSave.close()\n",
    "            print('It was created result: ',arquivoToSave)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(\"Error did file \", e)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivoToSaveError = '/home/pcorrea/erros.txt'\n",
    "\n",
    "def saveDocumentError(var, item,obj):\n",
    "    try:\n",
    "        with open(arquivoToSaveError, 'a') as toSave:\n",
    "            toSave.write('{} - qtd erro {} : {} \\n'.format(var,item,obj))\n",
    "            \n",
    "            toSave.close()\n",
    "            print('It was saver error: ',arquivoToSaveError)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(\"Error did file \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transTextBlob(sentences):\n",
    "    ##textblob\n",
    "    comentario_blob = TextBlob(sentences)\n",
    "    print(type(comentario_blob))\n",
    "    comentario_blob_us = comentario_blob.translate(to='us')\n",
    "    print(\"textblob traduziu: \",comentario_blob_us)\n",
    "    return comentario_blob, comentario_blob_us\n",
    "    ##textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transGoogle(sentences):\n",
    "    ##googletrans\n",
    "    import pandas as pd\n",
    "    from googletrans import Translator   \n",
    "    translator = Translator()\n",
    "    try:\n",
    "        translations = translator.translate([sentences], dest='en')\n",
    "        for translation in translations:\n",
    "            print(type(translation.text))\n",
    "            print(\"google traduziu: \", translation.text)\n",
    "    except AttributeError:\n",
    "         print(\"Error googletrans\")\n",
    "    ##googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "var 8527 x Descobri o Tokkuri pelo TripAdvisor, super bem avaliado a com razão. Os sushi man são muito competentes, peixes de qualidade e serviço gentil. Vale a pena, um restaurante para buscar qualidade e não quantidade. As lâminas de peixe cru temperadas com limão são divinas. \n",
      "\n",
      "\n",
      "Inglês:  I discovered Tokkuri through TripAdvisor, very well rated and rightly so. The sushi man are very competent, quality fish and kind service. It's worth it, a restaurant to look for quality, not quantity. The blades of raw fish seasoned with lemon are divine.\n",
      "sentence_br  Descobri o Tokkuri pelo TripAdvisor, super bem avaliado a com razão.\n",
      "sentence.sentiment.subjectivity:  0.4178571428571428\n",
      "Descobri o Tokkuri pelo TripAdvisor, super bem avaliado a com razão. : 0.4178571428571428\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  Os sushi man são muito competentes, peixes de qualidade e serviço gentil.\n",
      "sentence.sentiment.subjectivity:  0.8833333333333333\n",
      "Os sushi man são muito competentes, peixes de qualidade e serviço gentil. : 0.8833333333333333\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  Vale a pena, um restaurante para buscar qualidade e não quantidade.\n",
      "sentence.sentiment.subjectivity:  0.1\n",
      "Vale a pena, um restaurante para buscar qualidade e não quantidade. : 0.1\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  As lâminas de peixe cru temperadas com limão são divinas.\n",
      "sentence.sentiment.subjectivity:  0.3557692307692308\n",
      "As lâminas de peixe cru temperadas com limão são divinas. : 0.3557692307692308\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "\n",
      "\n",
      "var 8528 x É tipo um Outback Steakhouse, só que muito mais cool. A decoração é baseada no rock'n'roll (destaque na guitarras nas paredes e as escadarias que dão para o piso superior). Chope barato no horário do happy hour (18h - 20h de segunda a sexta), ótimos petiscos e sempre um bom show ao vivo. Atendimento cordial.\n",
      "Inglês:  It's like an Outback Steakhouse, only a lot cooler. The decor is based on rock'n'roll (highlighted by the guitars on the walls and the stairs leading to the upper floor). Cheap draft beer at happy hour (6 pm - 8 pm Monday to Friday), great snacks and always a good live show. Friendly service.\n",
      "sentence_br  É tipo um Outback Steakhouse, só que muito mais cool.\n",
      "sentence.sentiment.subjectivity:  1.0\n",
      "É tipo um Outback Steakhouse, só que muito mais cool. : 1.0\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  A decoração é baseada no rock'n'roll (destaque na guitarras nas paredes e as escadarias que dão para o piso superior).\n",
      "sentence.sentiment.subjectivity:  0.0\n",
      "A decoração é baseada no rock'n'roll (destaque na guitarras nas paredes e as escadarias que dão para o piso superior). : 0.0\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  Chope barato no horário do happy hour (18h - 20h de segunda a sexta), ótimos petiscos e sempre um bom show ao vivo.\n",
      "sentence.sentiment.subjectivity:  0.7100000000000001\n",
      "Chope barato no horário do happy hour (18h - 20h de segunda a sexta), ótimos petiscos e sempre um bom show ao vivo. : 0.7100000000000001\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  Atendimento cordial.\n",
      "sentence.sentiment.subjectivity:  0.5\n",
      "Atendimento cordial. : 0.5\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "\n",
      "\n",
      "var 8529 x Fizemos uma reserva para as 21:00, entendo que chegamos dez minutos atrasados, mas fomos até o balcão e perguntamos se quem tinha reserva precisava pegar a fila ou entrava direto, e nos falaram para pegar a fila. Depois de uma hora esperando, chegamos ao balcão e informamos sobre a reserva para a recepcionista, e ela informou que só seguram reserva até as 21:00 hs. Então porque não nos falaram quando fomos perguntar? Nos pouparia tempo e estresse. Isso sem contar o atendimento péssimo da recepcionista, fala gritando e com uma cara de quem está ali porque foi obrigada!!! Péssimo, numa próxima vez, vou pensar mil vezes antes de ir para esse lugar! Total falta de respeito e consideração com o cliente.\n",
      "Inglês:  We made a reservation for 21:00, I understand that we arrived ten minutes late, but we went to the counter and asked if anyone who had a reservation needed to take the queue or enter directly, and they told us to take the queue. After an hour of waiting, we arrived at the counter and informed the receptionist about the reservation, and she informed us that they only hold the reservation until 9:00 pm. So why didn't they tell us when we went to ask? It would save us time and stress. Not to mention the terrible service from the receptionist, she speaks screaming and with the face of someone who is there because she was obliged !!! Bad, next time, I will think a thousand times before I go to that place! Total lack of respect and consideration for the customer.\n",
      "sentence_br  Fizemos uma reserva para as 21:00, entendo que chegamos dez minutos atrasados, mas fomos até o balcão e perguntamos se quem tinha reserva precisava pegar a fila ou entrava direto, e nos falaram para pegar a fila.\n",
      "sentence.sentiment.subjectivity:  0.3333333333333333\n",
      "Fizemos uma reserva para as 21:00, entendo que chegamos dez minutos atrasados, mas fomos até o balcão e perguntamos se quem tinha reserva precisava pegar a fila ou entrava direto, e nos falaram para pegar a fila. : 0.3333333333333333\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  Depois de uma hora esperando, chegamos ao balcão e informamos sobre a reserva para a recepcionista, e ela informou que só seguram reserva até as 21:00 hs.\n",
      "sentence.sentiment.subjectivity:  1.0\n",
      "Depois de uma hora esperando, chegamos ao balcão e informamos sobre a reserva para a recepcionista, e ela informou que só seguram reserva até as 21:00 hs. : 1.0\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  Então porque não nos falaram quando fomos perguntar?\n",
      "sentence.sentiment.subjectivity:  0.0\n",
      "Então porque não nos falaram quando fomos perguntar? : 0.0\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  Nos pouparia tempo e estresse.\n",
      "sentence.sentiment.subjectivity:  0.0\n",
      "Nos pouparia tempo e estresse. : 0.0\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  Isso sem contar o atendimento péssimo da recepcionista, fala gritando e com uma cara de quem está ali porque foi obrigada!!!\n",
      "sentence.sentiment.subjectivity:  1.0\n",
      "Isso sem contar o atendimento péssimo da recepcionista, fala gritando e com uma cara de quem está ali porque foi obrigada!!! : 1.0\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  Péssimo, numa próxima vez, vou pensar mil vezes antes de ir para esse lugar!\n",
      "sentence.sentiment.subjectivity:  0.3333333333333333\n",
      "Péssimo, numa próxima vez, vou pensar mil vezes antes de ir para esse lugar! : 0.3333333333333333\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  Total falta de respeito e consideração com o cliente.\n",
      "sentence.sentiment.subjectivity:  0.75\n",
      "Total falta de respeito e consideração com o cliente. : 0.75\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "\n",
      "\n",
      "var 8530 x Bar tradicional de Sampa, pitoresco. Pequeno mas aconchegante. Destaque ao atendimento. Se tiver por perto vale a pena conhecer! \n",
      "Inglês:  Sampa's traditional, picturesque bar. Small but cozy. Highlight the service. If you are close by it is worth knowing!\n",
      "sentence_br  Bar tradicional de Sampa, pitoresco.\n",
      "sentence.sentiment.subjectivity:  0.75\n",
      "Bar tradicional de Sampa, pitoresco. : 0.75\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  Pequeno mas aconchegante.\n",
      "sentence.sentiment.subjectivity:  0.575\n",
      "Pequeno mas aconchegante. : 0.575\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  Destaque ao atendimento.\n",
      "sentence.sentiment.subjectivity:  0.0\n",
      "Destaque ao atendimento. : 0.0\n",
      "It was created result:  /home/pcorrea/salvo.txt\n",
      "sentence_br  Se tiver por perto vale a pena conhecer!\n",
      "sentence.sentiment.subjectivity:  0.1\n",
      "Se tiver por perto vale a pena conhecer! : 0.1\n",
      "It was created result:  /home/pcorrea/salvo.txt\n"
     ]
    }
   ],
   "source": [
    "var = 0\n",
    "errou = 0\n",
    "for x in df['reviewBody']:\n",
    "    try:\n",
    "        var = var + 1\n",
    "        if var > 0 and var <= 3:\n",
    "            print(\"**************\\n\")\n",
    "            print( \"var {} x {}\".format(var,x))\n",
    "            print(\"**************\\n\")\n",
    "            comentario_blob = TextBlob(x)\n",
    "\n",
    "            comentario_blob_us = comentario_blob.translate(to='us')\n",
    "            print(\"Inglês: \",comentario_blob_us)\n",
    "\n",
    "            for sentence_br, sentence in zip(comentario_blob.sentences, comentario_blob_us.sentences):\n",
    "                print(\"sentence_br \",sentence_br)\n",
    "                print(\"sentence.sentiment.subjectivity: \",sentence.sentiment.subjectivity)\n",
    "                if sentence_br is None:\n",
    "                    errou = errou + 1\n",
    "                    print(\"errou em {} - {} {}\".format(var,errou,x))\n",
    "                    saveDocumentError(var,errou,x)\n",
    "\n",
    "                elif var > 0 and var <= 3:\n",
    "                    print(sentence_br, ':', sentence.sentiment.subjectivity)\n",
    "                    saveDocument(var,sentence_br,sentence.sentiment.subjectivity, 'fim')\n",
    "                    \n",
    "                else:\n",
    "                    print(\"algum erro ocorreu em {}\".format(var))\n",
    "        elif var != 0:\n",
    "            var = var + 1\n",
    "        else:\n",
    "            print(\"Finalizou em \",var)\n",
    "            break\n",
    "    except:\n",
    "        print(\"ocorreu algum erro\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Abrir dataset_json.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
